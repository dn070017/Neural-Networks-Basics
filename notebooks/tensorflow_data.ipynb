{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages, Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from colorama import Fore, Style\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "def prepend_tab(target):\n",
    "    return f'{\"\":4}{target}'.replace('\\n', f'\\n{\"\":4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Predefined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtfds.list_builders\n",
      "- List predefined dataset\u001b[0m\n",
      "['abstract_reasoning', 'aflw2k3d', 'amazon_us_reviews', 'bair_robot_pushing_small', 'bigearthnet', 'binarized_mnist', 'binary_alpha_digits', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'chexpert', 'cifar10', 'cifar100', 'cifar10_corrupted', 'clevr', 'cnn_dailymail', 'coco', 'coco2014', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'curated_breast_imaging_ddsm', 'cycle_gan', 'deep_weeds', 'definite_pronoun_resolution', 'diabetic_retinopathy_detection', 'downsampled_imagenet', 'dsprites', 'dtd', 'dummy_dataset_shared_generator', 'dummy_mnist', 'emnist', 'eurosat', 'fashion_mnist', 'flores', 'food101', 'gap', 'glue', 'groove', 'higgs', 'horses_or_humans', 'image_label_folder', 'imagenet2012', 'imagenet2012_corrupted', 'imdb_reviews', 'iris', 'kitti', 'kmnist', 'lfw', 'lm1b', 'lsun', 'mnist', 'mnist_corrupted', 'moving_mnist', 'multi_nli', 'nsynth', 'omniglot', 'open_images_v4', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'patch_camelyon', 'pet_finder', 'quickdraw_bitmap', 'resisc45', 'rock_paper_scissors', 'rock_you', 'scene_parse150', 'shapes3d', 'smallnorb', 'snli', 'so2sat', 'squad', 'stanford_dogs', 'stanford_online_products', 'starcraft_video', 'sun397', 'super_glue', 'svhn_cropped', 'ted_hrlr_translate', 'ted_multi_translate', 'tf_flowers', 'titanic', 'trivia_qa', 'uc_merced', 'ucf101', 'visual_domain_decathlon', 'voc2007', 'wikipedia', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'xnli']\n",
      "\u001b[31m\n",
      "tfds.load\n",
      "- Load dataset\u001b[0m\n",
      "\u001b[35m    DatasetInfo\u001b[0m\n",
      "    tfds.core.DatasetInfo(\n",
      "        name='iris',\n",
      "        version=1.0.0,\n",
      "        description='This is perhaps the best known database to be found in the pattern recognition\n",
      "    literature. Fisher's paper is a classic in the field and is referenced\n",
      "    frequently to this day. (See Duda & Hart, for example.) The data set contains\n",
      "    3 classes of 50 instances each, where each class refers to a type of iris\n",
      "    plant. One class is linearly separable from the other 2; the latter are NOT\n",
      "    linearly separable from each other.\n",
      "    ',\n",
      "        urls=['https://archive.ics.uci.edu/ml/datasets/iris'],\n",
      "        features=FeaturesDict({\n",
      "            'features': Tensor(shape=(4,), dtype=tf.float32),\n",
      "            'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "        }),\n",
      "        total_num_examples=150,\n",
      "        splits={\n",
      "            'train': 150,\n",
      "        },\n",
      "        supervised_keys=('features', 'label'),\n",
      "        citation=\"\"\"@misc{Dua:2019 ,\n",
      "        author = \"Dua, Dheeru and Graff, Casey\",\n",
      "        year = \"2017\",\n",
      "        title = \"{UCI} Machine Learning Repository\",\n",
      "        url = \"http://archive.ics.uci.edu/ml\",\n",
      "        institution = \"University of California, Irvine, School of Information and Computer Sciences\"\n",
      "        }\"\"\",\n",
      "        redistribution_info=,\n",
      "    )\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'{Fore.RED}tfds.list_builders\\n- List predefined dataset{Style.RESET_ALL}')\n",
    "print(f'{tfds.list_builders()}')\n",
    "print(f'{Fore.RED}\\ntfds.load\\n- Load dataset{Style.RESET_ALL}')\n",
    "iris, info = tfds.load('iris', split='train', shuffle_files=True, with_info=True)\n",
    "print(f'{Fore.MAGENTA}{\"\":4}DatasetInfo{Style.RESET_ALL}')\n",
    "print(f'{prepend_tab(info)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow DatasetInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31minfo.name\n",
      "- Name of dataset\u001b[0m\n",
      "    iris\n",
      "\n",
      "\u001b[31minfo.description\n",
      "- Description of dataset\u001b[0m\n",
      "    This is perhaps the best known database to be found in the pattern recognition\n",
      "    literature. Fisher's paper is a classic in the field and is referenced\n",
      "    frequently to this day. (See Duda & Hart, for example.) The data set contains\n",
      "    3 classes of 50 instances each, where each class refers to a type of iris\n",
      "    plant. One class is linearly separable from the other 2; the latter are NOT\n",
      "    linearly separable from each other.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'{Fore.RED}info.name\\n- Name of dataset{Style.RESET_ALL}')\n",
    "print(f'{prepend_tab(info.name)}\\n')\n",
    "print(f'{Fore.RED}info.description\\n- Description of dataset{Style.RESET_ALL}')\n",
    "print(f'{prepend_tab(info.description)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Dataset Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtf.data.Dataset.range\n",
      "- Create a dataset with scalar from 1 to n.\u001b[0m\n",
      "    [0, 1, 2]\n",
      "\n",
      "\u001b[31mtf.data.Dataset.from_tensor_slices\n",
      "- Create a dataset from a tensor (the first axis will be the index for dataset)\n",
      "\u001b[0m    [array([0, 1, 2]), array([3, 4, 5])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'{Fore.RED}tf.data.Dataset.range')\n",
    "print(f'- Create a dataset with scalar from 1 to n.{Style.RESET_ALL}')\n",
    "dataset = tf.data.Dataset.range(3)\n",
    "print(f'{prepend_tab([element.numpy() for element in dataset])}\\n')\n",
    "print(f'{Fore.RED}tf.data.Dataset.from_tensor_slices')\n",
    "print(f'- Create a dataset from a tensor (the first axis will be the index for dataset)')\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor([[0, 1, 2], [3, 4, 5]]))\n",
    "print(f'{Style.RESET_ALL}{prepend_tab([element.numpy() for element in dataset])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Dataset Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mdataset.batch\n",
      "- Create batches of samples with given batch size\u001b[0m\n",
      "    \u001b[35mFeatures in batch 1\u001b[0m\n",
      "    [[6.5 3.2 5.1 2. ]\n",
      "     [7.7 2.6 6.9 2.3]\n",
      "     [6.2 2.2 4.5 1.5]\n",
      "     [4.9 3.1 1.5 0.1]\n",
      "     [6.3 3.3 4.7 1.6]]\n",
      "    \u001b[35mLabels in batch 1\u001b[0m\n",
      "    [2 2 1 0 1]\n",
      "    \u001b[35mFeatures in batch 2\u001b[0m\n",
      "    [[6.  2.9 4.5 1.5]\n",
      "     [5.8 2.7 3.9 1.2]\n",
      "     [6.8 2.8 4.8 1.4]\n",
      "     [5.4 3.4 1.5 0.4]\n",
      "     [5.6 2.9 3.6 1.3]]\n",
      "    \u001b[35mLabels in batch 2\u001b[0m\n",
      "    [1 1 1 0 1]\n",
      "\u001b[31m\n",
      "dataset.filter\n",
      "- Filter based on specific condition\u001b[0m\n",
      "    \u001b[35mNumber of examples\u001b[0m\n",
      "    7\n",
      "\u001b[31m\n",
      "dataset.map\n",
      "- Map functions to every element in the dataset\u001b[0m\n",
      "    [-6.1 -2.8 -4.7 -1.2]\n",
      "    [-5.7 -3.8 -1.7 -0.3]\n",
      "    [-7.7 -2.6 -6.9 -2.3]\n",
      "\u001b[31m\n",
      "iter\n",
      "- Get the iterators of the datasets\u001b[0m\n",
      "    <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x00000168CCA6C988>\n",
      "\u001b[31m\n",
      "tf.data.DatasetSpec\n",
      "- Get the dataset specification\u001b[0m\n",
      "    DatasetSpec(<_OptionsDataset shapes: {features: (4,), label: ()}, types: {features: tf.float32, label: tf.int64}>, TensorShape([]))\n"
     ]
    }
   ],
   "source": [
    "def negative_transform(x):\n",
    "    x['negative_features'] = -1 * x['features']\n",
    "    return x\n",
    "iris_shuffled = iris.shuffle(10)\n",
    "iris_example = iris_shuffled.take(10)\n",
    "iris_batches = iris_example.batch(5)\n",
    "print(f'{Fore.RED}dataset.batch\\n- Create batches of samples with given batch size{Style.RESET_ALL}')\n",
    "for i, batch in enumerate(iris_batches):\n",
    "    print(f'{\"\":4}{Fore.MAGENTA}Features in batch {i + 1}{Style.RESET_ALL}')\n",
    "    print(prepend_tab(batch['features'].numpy()))\n",
    "    print(f'{\"\":4}{Fore.MAGENTA}Labels in batch {i + 1}{Style.RESET_ALL}')\n",
    "    print(prepend_tab(batch['label'].numpy()))\n",
    "print(f'{Fore.RED}\\ndataset.filter\\n- Filter based on specific condition{Style.RESET_ALL}')\n",
    "iris_filtered = iris_example.filter(lambda x: tf.reduce_sum(x['features']) > 12.)\n",
    "print(f'{\"\":4}{Fore.MAGENTA}Number of examples{Style.RESET_ALL}')\n",
    "print(f'{\"\":4}{len(list(iris_filtered))}')\n",
    "print(f'{Fore.RED}\\ndataset.map\\n- Map functions to every element in the dataset{Style.RESET_ALL}')\n",
    "iris_modified = iris.take(3).map(negative_transform)\n",
    "for element in iris_modified:\n",
    "    print(f'{\"\":4}{element[\"negative_features\"]}')\n",
    "print(f'{Fore.RED}\\niter\\n- Get the iterators of the datasets{Style.RESET_ALL}')\n",
    "print(f'{\"\":4}{iter(iris)}')\n",
    "print(f'{Fore.RED}\\ntf.data.DatasetSpec\\n- Get the dataset specification{Style.RESET_ALL}')\n",
    "print(f'{\"\":4}{tf.data.DatasetSpec(iris)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
